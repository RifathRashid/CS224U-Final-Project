{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import financial_data_api as fd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "financial_data = fd.FinancialData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_articles_from_disk(data_directories):\n",
    "    counter = 0\n",
    "    articles = []\n",
    "    for directory in data_directories: \n",
    "        file_list = os.listdir(directory)\n",
    "        files_to_read = [os.path.join(directory, file) for file in file_list]\n",
    "        for file in files_to_read: \n",
    "            with open(file, 'r') as content_file:\n",
    "                content = content_file.read()\n",
    "                articles.append(content)\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths_from_tickers(tickers):\n",
    "    root_data_dir = 'article_data'\n",
    "    data_directories = [os.path.join(root_data_dir, t) for t in tickers]\n",
    "    return data_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles_for_tickers(tickers):\n",
    "    path_names = get_paths_from_tickers(tickers)\n",
    "    articles = read_articles_from_disk(path_names)\n",
    "    return set(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sp500_list():\n",
    "    companies = [s for s in pd.read_csv('constituents.csv', header=0)['Symbol']]\n",
    "    companies.remove('A')\n",
    "    companies.remove('T')\n",
    "    companies.remove('GOOG')\n",
    "    return companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_set(article, tickers):\n",
    "    words_found = set([])\n",
    "    ticker_set = set(tickers)\n",
    "    article = article.split()\n",
    "    for word in article:\n",
    "        if word in ticker_set: \n",
    "            words_found.add(word)\n",
    "    return words_found\n",
    "\n",
    "def get_occurrence_dict(articles):\n",
    "    counts_dict = {}\n",
    "    article_counter = 0\n",
    "    for a in all_articles:\n",
    "        company_set = get_company_set(a, sp_500_list)\n",
    "        pairs = itertools.combinations(company_set, 2)\n",
    "        pairs = set([tuple(sorted(list(p))) for p in pairs])\n",
    "        for p in pairs: \n",
    "            if p not in counts_dict:\n",
    "                counts_dict[p] = 0\n",
    "            counts_dict[p] += 1\n",
    "    return counts_dict   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_closest_neighbors(company_graph, node_source, num_neighbors):\n",
    "    neighbors = nx.shortest_path_length(company_graph, source=node_source, weight='weight')\n",
    "    nearest = []\n",
    "    counter = 0\n",
    "    for n in neighbors:\n",
    "        nearest.append(n)\n",
    "        if counter == num_neighbors:\n",
    "            break\n",
    "        counter += 1\n",
    "    return nearest[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_financial_metric_dict(tickers, metric):\n",
    "    result_dict = {}\n",
    "    for t in tickers: \n",
    "        data = financial_data.get_quarterly_data(t)\n",
    "        if t not in result_dict:\n",
    "            if data:\n",
    "                result_dict[t] = float(data[metric])\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['AAPL']\n",
    "tickers = ['BA', 'AAPL', 'GOOGL', 'CVX', 'MSFT', 'NFLX', 'XOM', 'GS', 'CAT', 'MMM', 'KO', 'DOW', 'HD', 'CSCO', 'AXP', 'TRV', 'MRK', 'UNH', 'PFE', 'NKE', 'MCD', 'JPM', 'JNJ', 'INTC', 'IBM']\n",
    "\n",
    "all_articles = get_articles_for_tickers(tickers)\n",
    "sp_500_list = get_sp500_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occurrence_dict = get_occurrence_dict(all_articles)\n",
    "node_set = set([])\n",
    "for pair in co_occurrence_dict:\n",
    "    node_set.add(pair[0])\n",
    "    node_set.add(pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occurrence_graph = nx.Graph()\n",
    "co_occurrence_graph.add_nodes_from(list(node_set))\n",
    "\n",
    "max_score = max([v for v in co_occurrence_dict.values()])\n",
    "\n",
    "for pair, score in co_occurrence_dict.items():\n",
    "    company_A = pair[0]\n",
    "    company_B = pair[1]\n",
    "    co_occurrence_graph.add_edge(company_A, company_B, weight=(1 - (score/max_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebit_data = get_financial_metric_dict(node_set, 'EPS Growth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "n_dict = {}\n",
    "for node in co_occurrence_graph.nodes():\n",
    "    neighbors = get_k_closest_neighbors(co_occurrence_graph, node, k)\n",
    "    neighbor_stats = []\n",
    "    n_dict[node] = neighbors\n",
    "\n",
    "    \n",
    "    \n",
    "    for n in neighbors: \n",
    "        if n in ebit_data:\n",
    "            neighbor_stats.append(ebit_data[n])\n",
    "    deviation = np.std(neighbor_stats)\n",
    "    results.append((node, deviation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dict['VZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_set = ['MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DOW', 'XOM', 'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JBM',\n",
    "'MCD', 'MRK', 'MSFT', 'NKE', 'PFE', 'PG', 'TRV', 'UNH', 'UTX', 'VZ', 'V', 'WMT', 'WBA', 'DIS']\n",
    "\n",
    "\n",
    "top = sorted([r for r in results if r[0] in inspect_set], key=lambda x:x[1])\n",
    "\n",
    "labels, ys = zip(*top)\n",
    "xs = np.arange(len(labels)) \n",
    "width = 1\n",
    "\n",
    "plt.bar(xs, ys, width, align='center')\n",
    "\n",
    "plt.xticks(xs, labels, rotation='vertical') #Replace default x-ticks with xs, then replace xs with labels\n",
    "#plt.yticks(ys)\n",
    "\n",
    "plt.savefig('netscore.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(top, key=lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
